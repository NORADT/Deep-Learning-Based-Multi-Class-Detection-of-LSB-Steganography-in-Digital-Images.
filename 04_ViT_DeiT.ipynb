{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT and DeiT Training for Malicious Payload Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import shutil\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configuration\n",
    "\n",
    "We define a `Config` class to hold all hyperparameters and settings. This includes paths for our new directory structure, making it easy to manage data, models, and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Project Directories\n",
    "    BASE_DIR = './payload_classification_project'\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    TRAIN_DATA_DIR = os.path.join(DATA_DIR, 'train')\n",
    "    TEST_DATA_DIR = os.path.join(DATA_DIR, 'test')\n",
    "    VAL_DATA_DIR = os.path.join(DATA_DIR, 'val')\n",
    "    MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "\n",
    "    # Training Parameters\n",
    "    IMAGE_SIZE = 224\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_FOLDS = 5\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Models to train\n",
    "    MODELS_TO_TRAIN = {\n",
    "        'ViT_224x224': 'vit_base_patch16_224',\n",
    "        'DeiT_224x224': 'deit_base_distilled_patch16_224'\n",
    "    }\n",
    "\n",
    "print(f\"Using device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Setup and Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregate_data_by_payload(original_data_path, new_base_path):\n",
    "    \"\"\"\n",
    "    Segregates the dataset into directories based on payload type (e.g., 'Benign', 'HiddenPayloadA').\n",
    "    \"\"\"\n",
    "    print(\"\\nSegregating data by payload type...\")\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        stego_path = os.path.join(original_data_path, split, split, 'stego')\n",
    "        clean_path = os.path.join(original_data_path, split, split, 'clean')\n",
    "        new_split_path = os.path.join(new_base_path, split)\n",
    "\n",
    "        if os.path.exists(stego_path):\n",
    "            print(f\"Processing stego images in {split} split...\")\n",
    "            for img_name in os.listdir(stego_path):\n",
    "                try:\n",
    "                    parts = img_name.split(\"_\")\n",
    "                    if len(parts) > 2:\n",
    "                        payload_class = parts[2]\n",
    "                        class_dir = os.path.join(new_split_path, payload_class)\n",
    "                        os.makedirs(class_dir, exist_ok=True)\n",
    "                        shutil.copy(os.path.join(stego_path, img_name), class_dir)\n",
    "                    else:\n",
    "                        print(f\"Skipping file with unexpected name format in stego: {img_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {img_name}: {e}\")\n",
    "\n",
    "        if os.path.exists(clean_path):\n",
    "            print(f\"Processing clean images in {split} split...\")\n",
    "            new_clean_path = os.path.join(new_split_path, 'Benign')\n",
    "            os.makedirs(new_clean_path, exist_ok=True)\n",
    "            for img_name in os.listdir(clean_path):\n",
    "                if os.path.isfile(os.path.join(clean_path, img_name)):\n",
    "                    shutil.copy(os.path.join(clean_path, img_name), new_clean_path)\n",
    "\n",
    "    print(\"Data segregation complete.\")\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"\n",
    "    Sets up the necessary directory structure and downloads/organizes data.\n",
    "    \"\"\"\n",
    "    print(\"--- Setting up project environment ---\")\n",
    "    for dir_path in [Config.BASE_DIR, Config.DATA_DIR, Config.TRAIN_DATA_DIR, Config.TEST_DATA_DIR, Config.VAL_DATA_DIR, Config.MODEL_DIR, Config.RESULTS_DIR]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    expected_train_classes = ['Benign', 'HiddenPayloadA']\n",
    "    data_already_segregated = all(os.path.exists(os.path.join(Config.TRAIN_DATA_DIR, cls)) for cls in expected_train_classes)\n",
    "\n",
    "    if data_already_segregated:\n",
    "        print(\"Dataset already downloaded and segregated.\")\n",
    "        return\n",
    "\n",
    "    print(\"Dataset not found or not organized. Starting download and segregation...\")\n",
    "    try:\n",
    "        download_path = kagglehub.dataset_download('marcozuppelli/stegoimagesdataset')\n",
    "        segregate_data_by_payload(download_path, Config.DATA_DIR)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download or process from Kaggle Hub. Error: {e}\")\n",
    "        raise\n",
    "\n",
    "    print(\"\\nEnvironment setup complete.\")\n",
    "\n",
    "def load_and_combine_data():\n",
    "    \"\"\"\n",
    "    Loads the segregated training and testing data and combines them for cross-validation.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Loading segregated data into DataFrames ---\")\n",
    "\n",
    "    def build_df_from_directory(directory):\n",
    "        image_files, labels = [], []\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"Warning: Directory not found: {directory}. Skipping.\")\n",
    "            return pd.DataFrame({'image_path': [], 'label': []})\n",
    "        for class_folder in os.listdir(directory):\n",
    "            class_path = os.path.join(directory, class_folder)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    image_files.append(os.path.join(class_path, img_file))\n",
    "                    labels.append(class_folder)\n",
    "        return pd.DataFrame({'image_path': image_files, 'label': labels})\n",
    "\n",
    "    train_df = build_df_from_directory(Config.TRAIN_DATA_DIR)\n",
    "    test_df = build_df_from_directory(Config.TEST_DATA_DIR)\n",
    "\n",
    "    if train_df.empty or test_df.empty:\n",
    "        raise ValueError(\"Training or testing DataFrame is empty. Data segregation may have failed.\")\n",
    "\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_df['encoded_label'] = label_encoder.fit_transform(combined_df['label'])\n",
    "\n",
    "    print(f\"Total combined data shape: {combined_df.shape}\")\n",
    "    print(\"Class distribution in combined set:\\n\", combined_df['label'].value_counts())\n",
    "\n",
    "    return combined_df, label_encoder\n",
    "\n",
    "# Execute the data preparation pipeline\n",
    "setup_environment()\n",
    "df, label_encoder = load_and_combine_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PyTorch Dataset\n",
    "\n",
    "The `PayloadDataset` class is updated to work with our new DataFrame. Instead of receiving pre-processed numpy arrays, it now takes the DataFrame and, in its `__getitem__` method, loads each image from the specified file path using PIL. It also ensures the image is converted to 'RGB' format to match the model's expected 3-channel input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PayloadDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch dataset for payload images loaded from a DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path and label\n",
    "        image_path = self.df.iloc[idx]['image_path']\n",
    "        label = self.df.iloc[idx]['encoded_label']\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Creation\n",
    "\n",
    "This helper function uses the `timm` library to easily create pretrained ViT or DeiT models. We specify the model name and the number of output classes, and `timm` handles the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Creates a ViT or DeiT model from the timm library with a custom classifier.\n",
    "    \"\"\"\n",
    "    model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Training and Evaluation Functions\n",
    "\n",
    "These are the core functions for the training loop:\n",
    "-   `train_one_epoch`: Iterates through the training data, performs a forward pass, calculates the loss, and updates the model weights.\n",
    "-   `evaluate`: Iterates through the validation data in `no_grad` mode, collects model predictions, and returns them for metric calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for images, labels in progress_bar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns predictions and true labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            \n",
    "            all_preds.extend(probabilities.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Main Execution: Training and Cross-Validation\n",
    "\n",
    "This is the main training block.\n",
    "\n",
    "1.  **Define Transforms**: Set up image transformations. Since we are not using data augmentation, this just includes resizing, converting to a tensor, and normalizing.\n",
    "2.  **Model Loop**: Iterate through each model specified in the `Config`.\n",
    "3.  **Cross-Validation**: Use `StratifiedKFold` to split the DataFrame. The indices from the split are used to create training and validation `PayloadDataset` instances for each fold.\n",
    "4.  **Training Loop & Evaluation**: For each fold, the model is trained for a set number of epochs, evaluating the ROC-AUC score on the validation set after each epoch.\n",
    "5.  **Report Results**: After all folds are complete, the average and standard deviation of the ROC-AUC scores are calculated and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (no data augmentation)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((Config.IMAGE_SIZE, Config.IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Loop through each model architecture\n",
    "for model_key, model_name in Config.MODELS_TO_TRAIN.items():\n",
    "    print(f\"\\n===== Starting Training for {model_key} =====\")\n",
    "    fold_results = []\n",
    "    \n",
    "    # Cross-Validation Loop\n",
    "    skf = StratifiedKFold(n_splits=Config.NUM_FOLDS, shuffle=True, random_state=42)\n",
    "    # Use the encoded labels for stratified splitting\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['encoded_label'])):\n",
    "        print(f\"\\n--- Fold {fold+1}/{Config.NUM_FOLDS} ---\")\n",
    "\n",
    "        # Split data for the current fold\n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = PayloadDataset(train_df, transform=data_transform)\n",
    "        val_dataset = PayloadDataset(val_df, transform=data_transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # Initialize model, criterion, and optimizer\n",
    "        model = create_model(model_name, num_classes).to(Config.DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE)\n",
    "        \n",
    "        # Training loop for epochs\n",
    "        best_auc = 0\n",
    "        for epoch in range(Config.EPOCHS):\n",
    "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, Config.DEVICE)\n",
    "            val_preds, val_labels = evaluate(model, val_loader, Config.DEVICE)\n",
    "            \n",
    "            # Calculate metrics (Multi-class ROC-AUC One-vs-Rest)\n",
    "            multi_auc = roc_auc_score(val_labels, val_preds, multi_class='ovr', average='macro')\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{Config.EPOCHS} | Train Loss: {train_loss:.4f} | Val ROC-AUC: {multi_auc:.4f}\")\n",
    "\n",
    "            if multi_auc > best_auc:\n",
    "                best_auc = multi_auc\n",
    "                # You could save the best model here if needed\n",
    "                # model_path = os.path.join(Config.MODEL_DIR, f'{model_key}_fold_{fold+1}_best.pth')\n",
    "                # torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        fold_results.append(best_auc)\n",
    "        print(f\"Best ROC-AUC for Fold {fold+1}: {best_auc:.4f}\")\n",
    "    \n",
    "    # Print average results for the model\n",
    "    avg_auc = np.mean(fold_results)\n",
    "    std_auc = np.std(fold_results)\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"Results for {model_key}:\")\n",
    "    print(f\"Average ROC-AUC over {Config.NUM_FOLDS} folds: {avg_auc:.4f} (+/- {std_auc:.4f})\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "print(\"All training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
