{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_markdown"
   },
   "source": [
    "# Comprehensive Technical Methodology for Malicious Payload Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports_setup_markdown"
   },
   "source": [
    "### 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "main_imports"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import zipfile\n",
    "import kagglehub\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, GlobalAveragePooling1D, GlobalAveragePooling2D, Conv2D,\n",
    "    MaxPooling2D, Flatten, Reshape, GRU, LSTM, Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from transformers import TFAutoModel\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import ViTImageProcessor, TFViTForImageClassification\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_markdown"
   },
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_vars"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Directory configurations\n",
    "    BASE_DIR = 'payload_detection_project'\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    TRAIN_DATA_DIR = os.path.join(DATA_DIR, 'train')\n",
    "    TEST_DATA_DIR = os.path.join(DATA_DIR, 'test')\n",
    "    VAL_DATA_DIR = os.path.join(DATA_DIR, 'val') # Though not used for final model training\n",
    "    MODEL_DIR = os.path.join(BASE_DIR, 'models')\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
    "\n",
    "    # Training configurations\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    N_FOLDS = 5\n",
    "    RANDOM_STATE = 42\n",
    "\n",
    "    # Transformer model names\n",
    "    DEIT_MODEL_NAME = 'facebook/deit-base-distilled-patch16-224'\n",
    "    VIT_MODEL_NAME = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep_markdown"
   },
   "source": [
    "### 3. Data Preparation: Segregation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "id": "KaFEE3zEMDSv",
    "outputId": "80df0f1c-8749-4e99-e6b8-7bf39273053a"
   },
   "outputs": [],
   "source": [
    "def segregate_data_by_payload(original_data_path, new_base_path):\n",
    "    \"\"\"\n",
    "    Segregates the dataset into directories based on payload type (e.g., 'Benign', 'HiddenPayloadA').\n",
    "    This is specifically for the structure of the 'stegoimagesdataset'.\n",
    "    \"\"\"\n",
    "    print(\"\\nSegregating data by payload type...\")\n",
    "    for split in ['train', 'test', 'val']: # The dataset structure has train, test, val subdirectories\n",
    "        stego_path = os.path.join(original_data_path, split, split, 'stego') # Adjust path based on dataset structure\n",
    "        clean_path = os.path.join(original_data_path, split, split, 'clean') # Adjust path based on dataset structure\n",
    "        new_split_path = os.path.join(new_base_path, split)\n",
    "\n",
    "        if os.path.exists(stego_path):\n",
    "            print(f\"Processing stego images in {split} split...\")\n",
    "            for img_name in os.listdir(stego_path):\n",
    "                try:\n",
    "                    # Expected format: carrier_method_payload_index.png\n",
    "                    parts = img_name.split(\"_\")\n",
    "                    if len(parts) > 2:\n",
    "                        payload_class = parts[2] # Extract payload type as class\n",
    "                        class_dir = os.path.join(new_split_path, payload_class)\n",
    "                        os.makedirs(class_dir, exist_ok=True)\n",
    "                        shutil.copy(os.path.join(stego_path, img_name), class_dir)\n",
    "                    else:\n",
    "                        print(f\"Skipping file with unexpected name format in stego: {img_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {img_name}: {e}\")\n",
    "\n",
    "        if os.path.exists(clean_path):\n",
    "            print(f\"Processing clean images in {split} split...\")\n",
    "            new_clean_path = os.path.join(new_split_path, 'Benign') # Name 'clean' as 'Benign' class\n",
    "            os.makedirs(new_clean_path, exist_ok=True) # Ensure directory exists\n",
    "            # Copy files individually instead of using copytree to avoid issues with existing dirs\n",
    "            for img_name in os.listdir(clean_path):\n",
    "                if os.path.isfile(os.path.join(clean_path, img_name)):\n",
    "                    shutil.copy(os.path.join(clean_path, img_name), new_clean_path)\n",
    "\n",
    "    print(\"Data segregation complete.\")\n",
    "\n",
    "import shutil\n",
    "def setup_environment():\n",
    "    \"\"\"\n",
    "    Sets up the necessary directory structure and downloads/organizes data using payload-based segregation.\n",
    "    \"\"\"\n",
    "    print(\"--- Setting up project environment ---\")\n",
    "\n",
    "    # Create base project directories\n",
    "    for dir_path in [Config.BASE_DIR, Config.DATA_DIR, Config.TRAIN_DATA_DIR, Config.TEST_DATA_DIR, Config.VAL_DATA_DIR, Config.MODEL_DIR, Config.RESULTS_DIR]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    # Check if data is already segregated\n",
    "    expected_train_classes = ['Benign', 'HiddenPayloadA']\n",
    "    data_already_segregated = all(os.path.exists(os.path.join(Config.TRAIN_DATA_DIR, cls)) for cls in expected_train_classes)\n",
    "\n",
    "    if data_already_segregated:\n",
    "        print(\"Dataset already downloaded and segregated.\")\n",
    "        return\n",
    "\n",
    "    print(\"Dataset not found or not organized. Starting download and segregation...\")\n",
    "\n",
    "    # Download data from Kaggle Hub\n",
    "    download_path = None\n",
    "    try:\n",
    "        zip_path = kagglehub.dataset_download('marcozuppelli/stegoimagesdataset')\n",
    "        download_path = 'stegoimagesdataset_unzipped'\n",
    "        shutil.copytree(zip_path, \"./stegoimagesdataset_unzipped\")\n",
    "        print(\"Path to copyied dataset files:\", download_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download or extract from Kaggle Hub. Error: {e}\")\n",
    "        raise\n",
    "\n",
    "    segregate_data_by_payload(download_path, Config.DATA_DIR)\n",
    "\n",
    "    print(\"\\nEnvironment setup complete.\")\n",
    "\n",
    "def load_and_combine_data():\n",
    "    \"\"\"\n",
    "    Loads the segregated training and testing data and combines them for cross-validation.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Loading segregated data into DataFrames ---\")\n",
    "\n",
    "    def build_df_from_directory(directory):\n",
    "        image_files = []\n",
    "        labels = []\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"Warning: Directory not found: {directory}. Skipping.\")\n",
    "            return pd.DataFrame({'image_path': [], 'label': []})\n",
    "\n",
    "        for class_folder in os.listdir(directory):\n",
    "            class_path = os.path.join(directory, class_folder)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    image_files.append(os.path.join(class_path, img_file))\n",
    "                    labels.append(class_folder)\n",
    "        return pd.DataFrame({'image_path': image_files, 'label': labels})\n",
    "\n",
    "    train_df = build_df_from_directory(Config.TRAIN_DATA_DIR)\n",
    "    test_df = build_df_from_directory(Config.TEST_DATA_DIR)\n",
    "\n",
    "    if train_df.empty or test_df.empty:\n",
    "        raise ValueError(\"Training or testing DataFrame is empty. Data segregation may have failed.\")\n",
    "\n",
    "    # Combine for cross-validation\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    combined_df['encoded_label'] = label_encoder.fit_transform(combined_df['label'])\n",
    "\n",
    "    print(f\"Total combined data shape: {combined_df.shape}\")\n",
    "    print(\"Class distribution in combined set:\\n\", combined_df['label'].value_counts())\n",
    "\n",
    "    return combined_df, label_encoder\n",
    "\n",
    "# Execute the data preparation pipeline\n",
    "setup_environment()\n",
    "df, label_encoder = load_and_combine_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_generator_markdown"
   },
   "source": [
    "### 4. Data Generator and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_generator_class"
   },
   "outputs": [],
   "source": [
    "class PayloadDataGenerator(Sequence):\n",
    "    \"\"\"Custom data generator for payload images, using Albumentations.\"\"\"\n",
    "    def __init__(self, df, batch_size, image_size, num_classes, augment=False, shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        # ðŸš€ CRITICAL FIX: Use the actual indices of the input DataFrame slice\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        if self.augment:\n",
    "            # Using the more advanced augmentation pipeline from new_payload_code.ipynb\n",
    "            self.augmentation = A.Compose([\n",
    "                A.RandomCrop(width=int(image_size[0]*0.8), height=int(image_size[1]*0.8), p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomBrightnessContrast(p=0.3),\n",
    "                A.RandomGamma(p=0.3),\n",
    "                A.ElasticTransform(p=0.3, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "                A.GridDistortion(p=0.3),\n",
    "                A.OpticalDistortion(p=0.3, distort_limit=2, shift_limit=0.5),\n",
    "                A.Resize(image_size[0], image_size[1]) # Resize back to target size\n",
    "            ])\n",
    "        else:\n",
    "            self.augmentation = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # ðŸš€ CRITICAL FIX: Select indices from the generator's indices list\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(batch_indices)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoche_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __data_generation(self, batch_indices):\n",
    "        # ðŸš€ CRITICAL FIX: Use .loc[] to access rows by index label\n",
    "        batch_df = self.df.loc[batch_indices]\n",
    "        X = np.empty((self.batch_size, *self.image_size, 3), dtype=np.float32) # Use float32 for normalization\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        for i, (idx, row) in enumerate(batch_df.iterrows()):\n",
    "            img_path = row['image_path']\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if self.augmentation:\n",
    "                augmented = self.augmentation(image=image)\n",
    "                image = augmented['image']\n",
    "\n",
    "            image = cv2.resize(image, self.image_size)\n",
    "\n",
    "            # ðŸš€ CRITICAL FIX: Add pixel normalization for the DeiT model\n",
    "            X[i,] = image\n",
    "            y[i] = row['encoded_label']\n",
    "\n",
    "        return X, to_categorical(y, num_classes=self.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_utils_markdown"
   },
   "source": [
    "### 5. Training and Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2HJ2l-Ab-Cq",
    "outputId": "7f2c8668-03f4-4316-a2aa-8196fb94771e"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_utils_code"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_builder, experiment_name, image_size, df, num_classes):\n",
    "    \"\"\"Trains and evaluates a given model using 5-fold cross-validation.\"\"\"\n",
    "    print(f\"\\n--- Starting Experiment: {experiment_name} ---\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=Config.RANDOM_STATE)\n",
    "    cv_scores = []\n",
    "    histories = []\n",
    "\n",
    "    X = df['image_path'].values\n",
    "    y = df['encoded_label'].values\n",
    "\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "    ]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f'\\n----- Fold {fold+1}/{Config.N_FOLDS} -----')\n",
    "\n",
    "        train_df = df.iloc[train_idx]\n",
    "        val_df = df.iloc[val_idx]\n",
    "\n",
    "        train_generator = PayloadDataGenerator(\n",
    "            df=train_df,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            image_size=image_size,\n",
    "            num_classes=num_classes,\n",
    "            augment=False\n",
    "        )\n",
    "\n",
    "        val_generator = PayloadDataGenerator(\n",
    "            df=val_df,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            image_size=image_size,\n",
    "            num_classes=num_classes,\n",
    "            augment=False,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "            model = model_builder(image_size, num_classes)\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        \n",
    "            model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=Config.EPOCHS,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        histories.append(history)\n",
    "\n",
    "        loss, accuracy = model.evaluate(val_generator, verbose=0)\n",
    "        print(f'Fold {fold+1} Validation Accuracy: {accuracy:.4f}')\n",
    "        cv_scores.append(accuracy)\n",
    "\n",
    "        # Save the model for this fold\n",
    "        model_save_path = os.path.join(Config.MODEL_DIR, f\"/content/drive/MyDrive/payload_new_models/{experiment_name}_fold_{fold+1}.keras\")\n",
    "        model.save(model_save_path)\n",
    "        print(f\"Model for fold {fold+1} saved to {model_save_path}\")\n",
    "\n",
    "    print(f\"\\n--- Results for {experiment_name} ---\")\n",
    "    print(f\"Scores for each fold: {[round(s, 4) for s in cv_scores]}\")\n",
    "    print(f\"Mean Accuracy: {np.mean(cv_scores):.4f}\")\n",
    "    print(f\"Standard Deviation: {np.std(cv_scores):.4f}\\n\")\n",
    "    return histories, cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "msED6JT5UFE9",
    "outputId": "5e2a9199-56e8-45fa-abac-ecfd2cc50e72"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U85rNwEBXdh8"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"/content/drive/MyDrive/payload_new_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BiIEIPqFs1V"
   },
   "outputs": [],
   "source": [
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnn_512_markdown"
   },
   "source": [
    "### 7. [NEW] Experiment 2: CNN (512x512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cnn_512_code",
    "outputId": "45860865-24cf-4deb-eeb1-f9d84c7826c5"
   },
   "outputs": [],
   "source": [
    "def create_cnn_model(image_size, num_classes):\n",
    "    \"\"\"Builds a standard CNN model.\"\"\"\n",
    "    input_shape = (*image_size, 3)\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "cnn_512_histories, cnn_512_scores = train_and_evaluate_model(\n",
    "    model_builder=create_cnn_model,\n",
    "    experiment_name='CNN_512x512',\n",
    "    image_size=(512, 512),\n",
    "    df=df,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9v5FzExG6qjf",
    "outputId": "0eb319e6-1a8e-4cd4-99e8-fc5b97f15474"
   },
   "outputs": [],
   "source": [
    "cnn_224_histories, cnn_224_scores = train_and_evaluate_model(\n",
    "    model_builder=create_cnn_model,\n",
    "    experiment_name='CNN_224x224',\n",
    "    image_size=(224, 224),\n",
    "    df=df,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnn_gru_markdown"
   },
   "source": [
    "### 8. [NEW] Experiment 3 & 4: CNN-GRU (512x512 and 224x224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cnn_gru_code",
    "outputId": "00e36410-bfc0-43bd-c3b1-d8e3a39bd555"
   },
   "outputs": [],
   "source": [
    "def create_cnn_gru_model(image_size, num_classes):\n",
    "    \"\"\"Builds a CNN-GRU model.\"\"\"\n",
    "    input_shape = (*image_size, 3)\n",
    "    cnn_base = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2))\n",
    "    ], name='cnn_base')\n",
    "\n",
    "    cnn_output_shape = cnn_base.output_shape\n",
    "    timesteps = cnn_output_shape[1]\n",
    "    features = cnn_output_shape[2] * cnn_output_shape[3]\n",
    "\n",
    "    model = Sequential([\n",
    "        cnn_base,\n",
    "        Reshape((timesteps, features)),\n",
    "        GRU(128, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "cnn_gru_512_histories, cnn_gru_512_scores = train_and_evaluate_model(\n",
    "    model_builder=create_cnn_gru_model,\n",
    "    experiment_name='CNN-GRU_512x512',\n",
    "    image_size=(512, 512),\n",
    "    df=df,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnn_lstm_markdown"
   },
   "source": [
    "### 9. [NEW] Experiment 5 & 6: CNN-LSTM (512x512 and 224x224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUDe8hlfFf58"
   },
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(image_size, num_classes):\n",
    "    \"\"\"Builds a CNN-LSTM model.\"\"\"\n",
    "    input_shape = (*image_size, 3)\n",
    "    cnn_base = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2))\n",
    "    ], name='cnn_base')\n",
    "\n",
    "    cnn_output_shape = cnn_base.output_shape\n",
    "    timesteps = cnn_output_shape[1]\n",
    "    features = cnn_output_shape[2] * cnn_output_shape[3]\n",
    "\n",
    "    model = Sequential([\n",
    "        cnn_base,\n",
    "        Reshape((timesteps, features)),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cnn_lstm_code",
    "outputId": "299825c1-ef78-4e07-cd5c-5dc2962ded93"
   },
   "outputs": [],
   "source": [
    "cnn_lstm_512_histories, cnn_lstm_512_scores = train_and_evaluate_model(\n",
    "    model_builder=create_cnn_lstm_model,\n",
    "    experiment_name='CNN-LSTM_512x512',\n",
    "    image_size=(512, 512),\n",
    "    df=df,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6eNzt83YFYn9",
    "outputId": "7a317803-4ee4-4312-ac9e-e9c3449c4ab0"
   },
   "outputs": [],
   "source": [
    "cnn_lstm_224_histories, cnn_lstm_224_scores = train_and_evaluate_model(\n",
    "    model_builder=create_cnn_lstm_model,\n",
    "    experiment_name='CNN-LSTM_224x224',\n",
    "    image_size=(224, 224),\n",
    "    df=df,\n",
    "    num_classes=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prediction_func_markdown"
   },
   "source": [
    "### 11. Universal Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prediction_demo_markdown"
   },
   "source": [
    "#### Demonstrate Prediction Function\n",
    "\n",
    "Here, we'll pick a few random images and test the prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hDp1FnSYItl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U-fNHnUUN0Q_",
    "outputId": "5fa3f89f-78d5-47d7-f8ff-b3a14c7fc576"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def evaluate_model(model_path, experiment_name, df, label_encoder_classes, is_binary=False):\n",
    "    \"\"\"Evaluates a single model.\"\"\"\n",
    "    print(f\"\\n--- Evaluating Model: {experiment_name} ({'Binary' if is_binary else 'Multi-class'}) ---\")\n",
    "\n",
    "    try:\n",
    "        model = load_model(model_path, compile=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_path}: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    input_shape = model.input_shape[1:3]\n",
    "\n",
    "    # Prepare data for evaluation\n",
    "    # Use the entire combined dataframe for evaluation as models were trained on folds\n",
    "    # This gives a comprehensive view across the dataset\n",
    "    eval_df = df.copy()\n",
    "\n",
    "    if is_binary:\n",
    "        # Create binary labels: 0 for Benign, 1 for Not Benign\n",
    "        eval_df['binary_label'] = eval_df['label'].apply(lambda x: 0 if x == 'Benign' else 1)\n",
    "        true_labels = eval_df['binary_label'].values\n",
    "        num_eval_classes = 2\n",
    "        target_names = ['Benign', 'Not Benign']\n",
    "    else:\n",
    "        true_labels = eval_df['encoded_label'].values\n",
    "        num_eval_classes = len(label_encoder_classes)\n",
    "        target_names = label_encoder_classes\n",
    "\n",
    "    # Create a generator for evaluation data\n",
    "    eval_generator = PayloadDataGenerator(\n",
    "        df=eval_df,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        image_size=input_shape,\n",
    "        num_classes=num_classes, # Need original num_classes for generator even if doing binary eval\n",
    "        augment=False,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Get predictions\n",
    "    # Predict returns probabilities for each class\n",
    "    predictions_probs = model.predict(eval_generator)\n",
    "    predicted_labels_encoded = np.argmax(predictions_probs, axis=1)\n",
    "\n",
    "    if is_binary:\n",
    "        # For binary task, map the multi-class predictions to binary predictions\n",
    "        # If the multi-class prediction is 'Benign', the binary prediction is 0.\n",
    "        # Otherwise, the binary prediction is 1.\n",
    "        predicted_labels_binary = [0 if label_encoder_classes[pred] == 'Benign' else 1 for pred in predicted_labels_encoded]\n",
    "        predicted_labels = predicted_labels_binary\n",
    "        # For binary ROC-AUC, we need the probability of the positive class (Not Benign)\n",
    "        # We need to sum probabilities of all non-Benign classes\n",
    "        benign_index = list(label_encoder_classes).index('Benign')\n",
    "        not_benign_probs = np.sum(np.delete(predictions_probs, benign_index, axis=1), axis=1)\n",
    "        roc_auc_score_val = roc_auc_score(true_labels, not_benign_probs)\n",
    "    else:\n",
    "        predicted_labels = predicted_labels_encoded\n",
    "        # For multi-class ROC-AUC, we use the one-vs-rest approach\n",
    "        true_labels_one_hot = to_categorical(true_labels, num_classes=num_eval_classes)\n",
    "        roc_auc_score_val = roc_auc_score(true_labels_one_hot, predictions_probs, average='macro')\n",
    "\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=target_names)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title(f'Confusion Matrix - {experiment_name} ({'Binary' if is_binary else 'Multi-class'})')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC-AUC Curve (Multi-class using One-vs-Rest, Binary for positive class)\n",
    "    if is_binary:\n",
    "        fpr, tpr, _ = roc_curve(true_labels, not_benign_probs)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_score_val:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Receiver Operating Characteristic - {experiment_name} (Binary)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Plot ROC-AUC for each class (One-vs-Rest)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i, target_name in enumerate(target_names):\n",
    "            fpr, tpr, _ = roc_curve(true_labels == i, predictions_probs[:, i])\n",
    "            plt.plot(fpr, tpr, lw=2, label=f'ROC curve of class {target_name} (area = {roc_auc_score(true_labels == i, predictions_probs[:, i]):.2f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Receiver Operating Characteristic - {experiment_name} (Multi-class)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    return report, cm, roc_auc_score_val, predicted_labels\n",
    "\n",
    "# --- Evaluate all models ---\n",
    "models_to_evaluate = {\n",
    "    'CNN_512x512_fold_5': (512, 512),\n",
    "    'CNN_224x224_fold_5': (224, 224),\n",
    "    'CNN-GRU_512x512_fold_5': (512, 512),\n",
    "    'CNN-GRU_224x224_fold_5': (224, 224),\n",
    "    'CNN-LSTM_512x512_fold_5': (512, 512),\n",
    "    'CNN-LSTM_224x224_fold_5': (224, 224),\n",
    "}\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, image_size in models_to_evaluate.items():\n",
    "    model_path = os.path.join(\"/content/drive/MyDrive/payload_new_models\", model_name + \".keras\") # Assume .keras extension\n",
    "    if os.path.exists(model_path):\n",
    "        # Evaluate Multi-class\n",
    "        report_mc, cm_mc, roc_auc_mc, preds_mc = evaluate_model(\n",
    "            model_path,\n",
    "            model_name,\n",
    "            df,\n",
    "            label_encoder.classes_,\n",
    "            is_binary=False\n",
    "        )\n",
    "\n",
    "        # Evaluate Binary\n",
    "        report_b, cm_b, roc_auc_b, preds_b = evaluate_model(\n",
    "            model_path,\n",
    "            model_name,\n",
    "            df,\n",
    "            label_encoder.classes_,\n",
    "            is_binary=True\n",
    "        )\n",
    "\n",
    "        evaluation_results[model_name] = {\n",
    "            'multi_class': {'report': report_mc, 'confusion_matrix': cm_mc, 'roc_auc': roc_auc_mc, 'predictions': preds_mc},\n",
    "            'binary': {'report': report_b, 'confusion_matrix': cm_b, 'roc_auc': roc_auc_b, 'predictions': preds_b}\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Model not found at {model_path}. Skipping evaluation for {model_name}.\")\n",
    "\n",
    "# Optional: You can now further process or display evaluation_results\n",
    "# For example, you could create a summary table of ROC-AUC scores\n",
    "print(\"\\n--- Summary of ROC-AUC Scores ---\")\n",
    "for model_name, results in evaluation_results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    if results['multi_class']['roc_auc'] is not None:\n",
    "        print(f\"  Multi-class ROC-AUC (macro avg): {results['multi_class']['roc_auc']:.4f}\")\n",
    "    if results['binary']['roc_auc'] is not None:\n",
    "         print(f\"  Binary ROC-AUC: {results['binary']['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ct5AR4bnN1DN",
    "outputId": "0a15d617-d5bf-4794-9fec-3bee1547c084"
   },
   "outputs": [],
   "source": [
    "! wget https://webpages.tuni.fi/imaging/tampere17/tampere17_color.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaOfSIANJ2mr",
    "outputId": "63bc8352-001b-4d1c-9351-df8c769ff3d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip tampere17_color.zip -d samples_to_embed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "MywccA6VKn79",
    "outputId": "87da9027-a78b-4827-83f4-d4e19363c926"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "sample_dir = \"/content/samples_to_embed/color\"\n",
    "image_files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if f.endswith('.png')]\n",
    "\n",
    "# Display a few sample images\n",
    "num_samples_to_show = 5\n",
    "selected_samples = image_files[:num_samples_to_show]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, img_path in enumerate(selected_samples):\n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, num_samples_to_show, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(os.path.basename(img_path))\n",
    "        plt.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load image {img_path}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lU0uEydCFt-O"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def _text_to_bits(data: bytes) -> np.ndarray:\n",
    "    \"\"\"Convert bytes to a 1-D numpy array of bits (0/1).\"\"\"\n",
    "    bits = np.unpackbits(np.frombuffer(data, dtype=np.uint8))\n",
    "    return bits.astype(np.uint8)\n",
    "\n",
    "def _bits_to_bytes(bits: np.ndarray) -> bytes:\n",
    "    \"\"\"Convert 1-D numpy array of bits to bytes.\"\"\"\n",
    "    # pad to a multiple of 8\n",
    "    pad = (-len(bits)) % 8\n",
    "    if pad:\n",
    "        bits = np.concatenate([bits, np.zeros(pad, dtype=np.uint8)])\n",
    "    arr = np.packbits(bits)\n",
    "    return arr.tobytes()\n",
    "\n",
    "def embed_text_lsb(image_path: str, text: str, out_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Embed text into image LSBs and save to out_path.\n",
    "    - image_path: path to input image (PNG recommended).\n",
    "    - text: string to embed (e.g., Ethereum address).\n",
    "    - out_path: path to save stego image.\n",
    "    \"\"\"\n",
    "    # Load image and convert to RGB\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    arr = np.array(img)\n",
    "    h, w, c = arr.shape\n",
    "    if c != 3:\n",
    "        raise ValueError(\"Expected RGB image with 3 channels\")\n",
    "\n",
    "    # Prepare payload: 32-bit length header (number of bytes) + UTF-8 bytes\n",
    "    payload_bytes = text.encode(\"utf-8\")\n",
    "    length = len(payload_bytes)\n",
    "    if length >= 2**32:\n",
    "        raise ValueError(\"Text too long to encode\")\n",
    "    header = struct.pack(\">I\", length)  # big-endian 4 bytes\n",
    "    full_bytes = header + payload_bytes\n",
    "    bits = _text_to_bits(full_bytes)  # 8 * (4 + length) bits\n",
    "\n",
    "    # Capacity: one bit per color channel per pixel if using all channels\n",
    "    capacity = h * w * 3\n",
    "    if bits.size > capacity:\n",
    "        raise ValueError(f\"Image too small; need {bits.size} bits but have {capacity}\")\n",
    "\n",
    "    # Flatten pixel array and replace LSBs\n",
    "    flat = arr.flatten()\n",
    "    # Replace LSB of first bits.size entries\n",
    "    flat[:bits.size] = (flat[:bits.size] & 0xFE) | bits\n",
    "    stego_arr = flat.reshape(arr.shape)\n",
    "\n",
    "    stego_img = Image.fromarray(stego_arr.astype(np.uint8), \"RGB\")\n",
    "    # Save as PNG to avoid compression losses\n",
    "    stego_img.save(out_path, format=\"PNG\")\n",
    "\n",
    "def extract_text_lsb(stego_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract embedded text from LSBs of an image saved by embed_text_lsb.\n",
    "    - stego_path: path to stego image (PNG recommended).\n",
    "    Returns the extracted UTF-8 string.\n",
    "    \"\"\"\n",
    "    img = Image.open(stego_path).convert(\"RGB\")\n",
    "    arr = np.array(img)\n",
    "    flat = arr.flatten()\n",
    "    # First read header: 32 bits = 4 bytes * 8\n",
    "    header_bits = flat[:32] & 1\n",
    "    header_bytes = _bits_to_bytes(header_bits)\n",
    "    length = struct.unpack(\">I\", header_bytes[:4])[0]\n",
    "    total_bits = (4 + length) * 8\n",
    "    if total_bits > flat.size:\n",
    "        raise ValueError(\"Declared payload length exceeds image capacity or image corrupted\")\n",
    "    payload_bits = flat[:total_bits] & 1\n",
    "    payload_bytes = _bits_to_bytes(payload_bits)[4:4+length]\n",
    "    return payload_bytes.decode(\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
